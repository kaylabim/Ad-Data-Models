{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06486c8",
   "metadata": {},
   "source": [
    "# Predicting user interactions with ads using data\n",
    "## Prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0f3066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'device_type', 'ad_position', 'browsing_history',\n",
       "       'time_of_day', 'click'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "addata = pd.read_csv('ad_click_dataset.csv')\n",
    "addata = addata.drop(['id', 'full_name'], axis=1)\n",
    "addata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe3165f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>click</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Non-Binary</th>\n",
       "      <th>device_type_Mobile</th>\n",
       "      <th>device_type_Tablet</th>\n",
       "      <th>ad_position_Side</th>\n",
       "      <th>ad_position_Top</th>\n",
       "      <th>browsing_history_Entertainment</th>\n",
       "      <th>browsing_history_News</th>\n",
       "      <th>browsing_history_Shopping</th>\n",
       "      <th>browsing_history_Social Media</th>\n",
       "      <th>time_of_day_Evening</th>\n",
       "      <th>time_of_day_Morning</th>\n",
       "      <th>time_of_day_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  click  gender_Male  gender_Non-Binary  device_type_Mobile  \\\n",
       "0  22.0      1        False              False               False   \n",
       "1   NaN      1         True              False               False   \n",
       "2  41.0      1        False               True               False   \n",
       "3  34.0      1         True              False               False   \n",
       "4  39.0      0        False               True               False   \n",
       "\n",
       "   device_type_Tablet  ad_position_Side  ad_position_Top  \\\n",
       "0               False             False             True   \n",
       "1               False             False             True   \n",
       "2               False              True            False   \n",
       "3               False             False            False   \n",
       "4               False             False            False   \n",
       "\n",
       "   browsing_history_Entertainment  browsing_history_News  \\\n",
       "0                           False                  False   \n",
       "1                            True                  False   \n",
       "2                           False                  False   \n",
       "3                            True                  False   \n",
       "4                           False                  False   \n",
       "\n",
       "   browsing_history_Shopping  browsing_history_Social Media  \\\n",
       "0                       True                          False   \n",
       "1                      False                          False   \n",
       "2                      False                          False   \n",
       "3                      False                          False   \n",
       "4                      False                           True   \n",
       "\n",
       "   time_of_day_Evening  time_of_day_Morning  time_of_day_Night  \n",
       "0                False                False              False  \n",
       "1                False                 True              False  \n",
       "2                False                False               True  \n",
       "3                 True                False              False  \n",
       "4                False                 True              False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Imputing categorical features ######\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "cat_cols = ['gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day']\n",
    "cat_imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "addata[cat_cols] = cat_imputer.fit_transform(addata[cat_cols])\n",
    "\n",
    "# Encoding categorical variables \n",
    "addata = pd.get_dummies(addata, columns = cat_cols, drop_first= True)\n",
    "display(addata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9dcf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Imputing numerical feature ######\n",
    "# Edit: because feature importance seems to be REALLY high for the age feature, going to try out different imputations \n",
    "\n",
    "# # Simple imputer\n",
    "# num_imputer = SimpleImputer(strategy = 'median')\n",
    "# addata['age'] = num_imputer.fit_transform(addata[['age']])\n",
    "\n",
    "# # Aribtrary value imputation \n",
    "# addata.fillna({'age': -999}, inplace=True)\n",
    "\n",
    "# Multiple Imputation (miceforest)\n",
    "import miceforest as mf \n",
    "kernel = mf.ImputationKernel(\n",
    "    data = addata, \n",
    "    save_all_iterations_data=True, \n",
    "    random_state=42\n",
    ")\n",
    "kernel.mice(iterations=2)\n",
    "addata = kernel.complete_data()\n",
    "\n",
    "mask = addata['age'].notna()\n",
    "addata_a = addata[mask].copy()\n",
    "addata_na = addata[~mask].copy()\n",
    "\n",
    "features = [col for col in addata.columns if col not in ['age', 'click']]\n",
    "\n",
    "X = addata_a[features]\n",
    "y = addata_a['age']\n",
    "\n",
    "# # End Tail Imputation \n",
    "# from feature_engine.imputation import EndTailImputer\n",
    "# end_tail_imputer = EndTailImputer(imputation_method='gaussian', tail='right', fold=3, variables=['age'])\n",
    "# end_tail_imputer.fit(addata)\n",
    "# addata = end_tail_imputer.transform(addata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7bb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data \n",
    "X = addata.drop('click', axis=1)\n",
    "y = addata['click']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485df7c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d1ace39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.874\n",
      "\n",
      "Classification Report (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81       707\n",
      "           1       0.89      0.92      0.90      1293\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.85      0.86      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 553  154]\n",
      " [  98 1195]]\n",
      "\n",
      "AUC-ROC: 0.9296139259268983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "############## Random forest model \n",
    "rf = RandomForestClassifier(random_state=2)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report (Random Forest):\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nAUC-ROC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4d013",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c66fa088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Accuracy: 0.873\n",
      "\n",
      "Classification Report (XGBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       707\n",
      "           1       0.90      0.90      0.90      1293\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 579  128]\n",
      " [ 126 1167]]\n",
      "\n",
      "AUC-ROC: 0.9263847001206583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaylakim/Desktop/Ad-Data-Models/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [11:31:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"colample_bytree\", \"object\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "############### XGBoost algorithm \n",
    "XGBoost_model = XGBClassifier(\n",
    "    object='binary:logistic', \n",
    "    random_state=2, \n",
    "    n_estimators=200, \n",
    "    max_depth=7,\n",
    "    learning_rate=0.2,\n",
    "    subsample=0.8, \n",
    "    colample_bytree=0.8,\n",
    "    scale_pos_weight= float(len(y_train[y_train == 0]) / len(y_train[y_train == 1]))\n",
    ")\n",
    "\n",
    "XGBoost_model.fit(X_train, y_train)\n",
    "y_pred_xgboost = XGBoost_model.predict(X_test)\n",
    "\n",
    "print(\"\\nXGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgboost))\n",
    "print(\"\\nClassification Report (XGBoost):\\n\", classification_report(y_test, y_pred_xgboost))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgboost))\n",
    "print(\"\\nAUC-ROC:\", roc_auc_score(y_test, XGBoost_model.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "#### Using gridsearchcv for best xgboost parameters \n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'n_estimators': [50, 100, 200]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(XGBClassifier(objective='binary:logistic', random_state=2), param_grid, cv=5, n_jobs=-1)\n",
    "# grid.fit(X_train, y_train)\n",
    "# print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6ed5d",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3ab209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier Accuracy: 0.8765\n",
      "\n",
      "Classification Report (Decision Tree Classifier):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       707\n",
      "           1       0.89      0.92      0.91      1293\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.87      0.86      0.86      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 557  150]\n",
      " [  97 1196]]\n",
      "\n",
      "AUC-ROC: 0.8787618238124774\n"
     ]
    }
   ],
   "source": [
    "######## Decison Tree Classifier \n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = {classes[i]: weights[i] for i in range(len(classes))}\n",
    "\n",
    "DTC_model = DecisionTreeClassifier(\n",
    "    criterion = 'entropy', \n",
    "    splitter = 'best', \n",
    "    max_depth = None, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    class_weight=None, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "DTC_model.fit(X_train, y_train)\n",
    "y_pred_DTC = DTC_model.predict(X_test)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier Accuracy:\", accuracy_score(y_test, y_pred_DTC))\n",
    "print(\"\\nClassification Report (Decision Tree Classifier):\\n\", classification_report(y_test, y_pred_DTC))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_DTC))\n",
    "print(\"\\nAUC-ROC:\", roc_auc_score(y_test, DTC_model.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# ########## Again, using gridsearchcv for parameter tuning \n",
    "# param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [3, 5, 7, 10, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'class_weight': ['balanced', class_weights, None]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# # print(grid.best_params_, grid.best_estimator_)\n",
    "# best_clf = grid.best_estimator_\n",
    "# print(accuracy_score(y_test, best_clf.predict(X_test)))\n",
    "\n",
    "# ########## Checking for feature importance \n",
    "# importances = DTC_model.feature_importances_\n",
    "# feature_importance = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "# print(feature_importance.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# # Assuming X and y are already defined\n",
    "# models = [\n",
    "#     ('LR', LogisticRegression()),\n",
    "#     ('LDA', LinearDiscriminantAnalysis()),\n",
    "#     ('KNN', KNeighborsClassifier()),\n",
    "#     ('CART', DecisionTreeClassifier()),\n",
    "#     ('RF', RandomForestClassifier()),\n",
    "#     ('NB', GaussianNB()),\n",
    "#     ('SVM', SVC())\n",
    "# ]\n",
    "\n",
    "# results = []\n",
    "# names = []\n",
    "# for name, model in models:\n",
    "#     kfold = KFold(n_splits=10, shuffle=True, random_state=2)\n",
    "#     cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     print(f\"{name}: {cv_results.mean():.3f} ({cv_results.std():.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
